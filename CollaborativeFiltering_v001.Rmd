---
title: "Collaborative Filtering"
author: "davegoblue"
date: "June 15, 2016"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Background and Overview  
Collaborative filtering is an algorithm explored in the Ng Coursera "Machine Learning" course.  I am curious about the implications of choosing to normalize the response variable (movie rating) by subtracting its mean, as opposed to allowing the system to determine how to account for different movies having different means.  

## Analysis
###_Data Loading_  
Data is loaded from the MATLAB files that were supplied during the course.  Specifically, there is data on:  
  
* Matrices for movie ratings by user/movie  
* Initial theta matrices for predicting movie ratings as supplied by the instructors  
  
The data are loaded and inspected using the R.matlab() library:
```{r}
library(R.matlab, quietly=TRUE)

# Part 1: Load the movie ratings

matPath <- "../../../OctaveDirectory/Week09/"  # Using relative path
wgtData <- "ex8_movies.mat"

listMATData <- readMat(paste0(matPath, wgtData))
str(listMATData)  # Check that as expected - list with two items, $Y, $R

# Movie ratings are the ratings (movie x user)
# mtxSparse is a 1/0 indicator for whether the user has rated the movie
movieRatings <- listMATData$Y
mtxSparse <- listMATData$R

str(movieRatings)  # Validate that 1682x943 matrix (1682 movies, 943 users)
str(mtxSparse)  # Validate that 1682x943 matrix


# Part 2: Load the initial thetas

matPath <- "../../../OctaveDirectory/Week09/"  # Using relative path
wgtData <- "ex8_movieParams.mat"

listMATData <- readMat(paste0(matPath, wgtData))

# Will only keep the $X and $Theta items; other fields can be derived
str(listMATData)

mtxX <- listMATData$X
mtxTheta <- listMATData$Theta

str(mtxX)  # Validate that 1682x10 matrix (1682 movies, 10 features)
str(mtxTheta)  # Validate that 943x10 matrix (943 users, 10 features)

```
  
###_Function Declarations for Optimization_  
Next, functions are created to enable optimization to be run.  The functions include a cost calculation and then a gradient calculation:  
```{r}

cofiCost <- function(vecMatrix, mtxY, mtxR, nUser, nMovie, nFeature, lambda) {
    
    # Roll vecMatrix back to feature matrix and theta matrix
    keyCut <- nMovie * nFeature
    vecX <- vecMatrix[1:keyCut]
    vecTheta <- vecMatrix[(keyCut+1):length(vecMatrix)]
    useX <- matrix(data=vecX, nrow=nMovie, ncol=nFeature, byrow=FALSE)
    useTheta <- matrix(data=vecTheta, nrow=nUser, ncol=nFeature, byrow=FALSE)
    
    # Calculate cost
    movJ <- 0.5 * sum( ( (useX %*% t(useTheta) - mtxY)^2)[mtxR==1] )
    movJ <- movJ + 0.5 * lambda * ( sum(useX^2) + sum(useTheta^2) )
    
    return(movJ)
}

cofiGrad <- function(vecMatrix, mtxY, mtxR, nUser, nMovie, nFeature, lambda) {
    
    # Roll vecMatrix back to feature matrix and theta matrix
    keyCut <- nMovie * nFeature
    vecX <- vecMatrix[1:keyCut]
    vecTheta <- vecMatrix[(keyCut+1):length(vecMatrix)]
    useX <- matrix(data=vecX, nrow=nMovie, ncol=nFeature, byrow=FALSE)
    useTheta <- matrix(data=vecTheta, nrow=nUser, ncol=nFeature, byrow=FALSE)
    
    # Calculate gradients
    gradX <- ((useX %*% t(useTheta) - mtxY) * mtxR) %*% useTheta + (lambda * useX)
    gradTheta <- t((useX %*% t(useTheta) - mtxY) * mtxR) %*% useX + (lambda * useTheta)
    
    return(c(as.vector(gradX), as.vector(gradTheta)))
    
}

```
  
Further, the cost function is tested to ensure that it is consistent with the results the professor suggests to expect:  
```{r}
# Modify them for the test
nUser <- 4
nMovie <- 5
nFeature <- 3

# Validate that ~22.22
cofiCost(vecMatrix = c(as.vector(mtxX[1:nMovie, 1:nFeature]), as.vector(mtxTheta[1:nUser, 1:nFeature])),
         mtxY = movieRatings[1:nMovie, 1:nUser], mtxR = mtxSparse[1:nMovie, 1:nUser], nUser=nUser,
         nMovie=nMovie, nFeature=nFeature, lambda=0
         )

# Validate that ~31.34
cofiCost(vecMatrix = c(as.vector(mtxX[1:nMovie, 1:nFeature]), as.vector(mtxTheta[1:nUser, 1:nFeature])),
         mtxY = movieRatings[1:nMovie, 1:nUser], mtxR = mtxSparse[1:nMovie, 1:nUser], nUser=nUser,
         nMovie=nMovie, nFeature=nFeature, lambda=1.5
         )

# Capture these properly for remainder of program
nUser <- nrow(mtxTheta)
nMovie <- nrow(mtxX)
nFeature <- ncol(mtxX)

# Confirm that runs OK for full dataset also
cofiCost(vecMatrix = c(as.vector(mtxX), as.vector(mtxTheta)), mtxY = movieRatings, 
         mtxR = mtxSparse, nUser=nUser, nMovie=nMovie, nFeature=nFeature, lambda=0
         )
# Confirm that runs OK for full dataset also
cofiCost(vecMatrix = c(as.vector(mtxX), as.vector(mtxTheta)), mtxY = movieRatings, 
         mtxR = mtxSparse, nUser=nUser, nMovie=nMovie, nFeature=nFeature, lambda=10
         )

```
  
It appears that the cost function is working as it should.  The cost using the instructors inputs is 74,000 of which 28,000 is driven by mismatched movies, and 46,000 is driven by penalties induced by lambda=10.
  
###_Assessing Movie Recommendations_  
The quality of the movie recommendations depends on the degree of similarity between the predictions and the actual ratings, assessed only where a rating has been given.  A function is created to predict the approrpiate ratings and to plot their relationship to the actual ratings:  
```{r}
assessRatings <- function(vecMatrix, mtxY, mtxR, nUser, nMovie, nFeature, lambda, 
                          useTitle=FALSE, normData=NULL, getPredOnly=FALSE
                          ) {
    
    # Roll vecMatrix back to feature matrix and theta matrix
    keyCut <- nMovie * nFeature
    vecX <- vecMatrix[1:keyCut]
    vecTheta <- vecMatrix[(keyCut+1):length(vecMatrix)]
    useX <- matrix(data=vecX, nrow=nMovie, ncol=nFeature, byrow=FALSE)
    useTheta <- matrix(data=vecTheta, nrow=nUser, ncol=nFeature, byrow=FALSE)

    # Calculate the projected movie ratings
    predRatings <- useX %*% t(useTheta)
    
    # Add back the means if requested
    if (length(normData) > 0) {
        # Add the averages back to the predictions
        predRatings <- predRatings + normData * mtxR
        # Add the averages back to the raw data
        mtxY <- mtxY + normData * mtxR
    }
    
    # Keep functionality to just return the predictions; user discretion
    if (getPredOnly == TRUE) {
        return(predRatings)
    }
    
    # Provided the user does not just want the predictions, run their comparisons
    # Create the confusion matrix assuming all ratings are forced to be 1-5
    cmRound <- confusionMatrix(pmin(5, pmax(1, round(predRatings[mtxR==1], 0) ) ), mtxY[mtxR==1])
    
    # Create the lm, and without assuming all ratings are forced to be 1-5
    lmAssess <- lm(predRatings[mtxR==1] ~ mtxY[mtxR==1])
    print(summary(lmAssess))
    
    par(mfrow=c(1, 2))
    
    # Create a histogram of the ratings
    hist(x=predRatings[mtxR==1], col=rgb(0.5,0,0,0.25), xlab="Rating", 
         main=ifelse(useTitle == FALSE, "Instructor Inputs (R == 1)", useTitle),
         breaks=seq(-2.5,7.5,by=1)
         )
    hist(x=mtxY[mtxR==1], col=rgb(0,0,0.5,0.25), add=TRUE, breaks=seq(-2.5,7.5,by=1))
    legend("topleft", legend=c("Actual", "Predicted", "Overlap"), pch=20, cex=0.9, pt.cex=3,
           col=c(rgb(0,0,0.5,0.25), rgb(0.5,0,0,0.25), rgb(0.25,0,0.25,0.5))
           )
    
    # Create a boxplot of the ratings
    trueRatings <- 0.5 * round(2*mtxY, 0)[mtxR==1]
    boxplot(predRatings[mtxR==1] ~ trueRatings, col="light blue", 
            xlab="Actual Rating", ylab="Predicted Rating",
            main=ifelse(useTitle == FALSE, "Instructor Inputs (R == 1)", useTitle)
            )
    text(x=2.2, y=0.3, paste0("R^2: ", round(summary(lmAssess)$r.squared, 2) ), adj=c(0, 0), cex=0.8 )
    text(x=2.2, y=-0.1, paste0("Accur: ", round(cmRound$overall[[1]], 2) ), adj=c(0, 0) , cex=0.8)
    text(x=4, y=0.3, paste0("Inter: ", round(coef(lmAssess)[[1]], 2) ), adj=c(0, 0) , cex=0.8)
    text(x=4, y=-0.1, paste0("Slope: ", round(coef(lmAssess)[[2]], 2) ), adj=c(0, 0) , cex=0.8)
    
    
    par(mfrow=c(1, 1))
    
    return(cmRound)
}
```
  
Next, the function is called to check the instructors inputs:  
```{r}
library(caret, quietly=TRUE)

# Assess the original movie data from the instructor
cmOrig <- assessRatings(vecMatrix = c(as.vector(mtxX), as.vector(mtxTheta)), mtxY = movieRatings, 
                        mtxR = mtxSparse, nUser=nUser, nMovie=nMovie, nFeature=nFeature, lambda=10
                        )
cmOrig

```
  
###_Creating Movie Recommendations (Normalized)_  
Creating movie recommendations requires two steps.  First, input values need to be randomized in to the prediction matrices, to ensure that the symmetries are broken.  Second, the inputs need to be optimized, whether using mini-batch, a global optimizer, or some other technique.  
  
For this example, we will further take the step of normalizing (subtracting the mean) all actual movie ratings prior to the optimization.  This means that thetas will not need to do any work coming up with the mean component, a significant savings when all coefficient-squared are penalized by 10.  
  
First, the lambda parameter is set to 10, the random initial matrices are set, and the normalized ratings data are created:  
```{r}
useLambda=10

# Initialize mtxX and mtxTheta using N(0, 1) -- seems very high, but done to match Octave
set.seed(1615161453)
simTheta <- matrix(rnorm(length(mtxTheta)), nrow=nrow(mtxTheta))
simX <- matrix(rnorm(length(mtxX)), nrow=nrow(mtxX))

# Create the movie averages and normalized ratings
movSum <- apply(movieRatings, 1, FUN=sum)
movCount <- apply(mtxSparse, 1, FUN=sum)
movAvg <- movSum / movCount

normRatings <- movieRatings - movAvg * mtxSparse
```
  
Next, optimization is run using the CG method capped at 250 iterations.  This is cached to avoid continually processing the same data:  
```{r, cache=TRUE}

vecMatrix = c(as.vector(simX), as.vector(simTheta))

startTime <- proc.time()
movNorm250 <- optim(par=vecMatrix, fn=cofiCost, gr=cofiGrad, mtxY=normRatings, mtxR=mtxSparse,
                    nUser=ncol(normRatings), nMovie=nrow(normRatings), nFeature=ncol(mtxTheta), 
                    lambda=useLambda, control=list(maxit=250), method="CG"
                 )
proc.time() - startTime

```
  
Then, the normalized movie ratings are assessed, with the request to add back the movie averages everywhere:  
```{r}
# Run the standard process
cmNorm <- assessRatings(vecMatrix=movNorm250$par, mtxY=normRatings, mtxR=mtxSparse, 
                        nUser=ncol(normRatings), nMovie=nrow(normRatings), nFeature=ncol(mtxTheta),
                        lambda=useLambda, useTitle="Normalized CG 250 (R == 1)", normData=movAvg
                        )
cmNorm

# Report back the costs using lambda=0 (true prediction error) and lambda=10 (regularized prediction error)
cofiCost(vecMatrix=movNorm250$par, mtxY=normRatings, mtxR=mtxSparse, 
         nUser=ncol(normRatings), nMovie=nrow(normRatings), nFeature=ncol(mtxTheta), lambda=0
         )
cofiCost(vecMatrix=movNorm250$par, mtxY=normRatings, mtxR=mtxSparse, 
         nUser=ncol(normRatings), nMovie=nrow(normRatings), nFeature=ncol(mtxTheta), lambda=10
         )

```
  
###_Creating Movie Recommendations (Non-Normalized)_  
In this step, we instead use the raw movie ratings in the algorithm, running the same process as before.  The same initial theta matrix is used for consistency, though this likely disadvantages the non-normalized process since it will need to seek out a surrogate for intercept.  Optimization is again run for CG 250:  
```{r, cache=TRUE}

vecMatrix = c(as.vector(simX), as.vector(simTheta))

startTime <- proc.time()
movAsIs250 <- optim(par=vecMatrix, fn=cofiCost, gr=cofiGrad, mtxY=movieRatings, mtxR=mtxSparse,
                    nUser=ncol(movieRatings), nMovie=nrow(movieRatings), nFeature=ncol(mtxTheta), 
                    lambda=useLambda, control=list(maxit=250), method="CG"
                 )
proc.time() - startTime

```
  
And, the predicted movie ratings are assessed, defaulted to leave all of the movie averages alone:  
```{r}
# Run the standard process
cmAsIs <- assessRatings(vecMatrix=movAsIs250$par, mtxY=movieRatings, mtxR=mtxSparse, 
                        nUser=ncol(movieRatings), nMovie=nrow(movieRatings), nFeature=ncol(mtxTheta), 
                        lambda=useLambda, useTitle="As-Is CG 250 (R == 1)"
                        )
cmAsIs

# Report back the costs using lambda=0 (true prediction error) and lambda=10 (regularized prediction error)
cofiCost(vecMatrix=movAsIs250$par, mtxY=movieRatings, mtxR=mtxSparse, 
         nUser=ncol(movieRatings), nMovie=nrow(movieRatings), nFeature=ncol(mtxTheta), lambda=0
         )
cofiCost(vecMatrix=movAsIs250$par, mtxY=movieRatings, mtxR=mtxSparse, 
         nUser=ncol(movieRatings), nMovie=nrow(movieRatings), nFeature=ncol(mtxTheta), lambda=10
         )

```
  
###_Creating Movie Recommendations (Non-Normalized)_  
Lastly, movie ratings are created assuming lambda=5, and with the "as is" method.  This is an attempt to replicate the 28k (lambda 0) / 74k (lambda 10) as seen from the original instructor data.  Optimization is again run for CG 250:  
```{r, cache=TRUE}

vecMatrix = c(as.vector(simX), as.vector(simTheta))

startTime <- proc.time()
movAsIs250lam5 <- optim(par=vecMatrix, fn=cofiCost, gr=cofiGrad, mtxY=movieRatings, mtxR=mtxSparse,
                        nUser=ncol(movieRatings), nMovie=nrow(movieRatings), nFeature=ncol(mtxTheta), 
                        lambda=5, control=list(maxit=250), method="CG"
                        )
proc.time() - startTime

```
  
Accuracy is then run as per previous, again defaulted to leave the raw movie ratings alone:  
```{r}
# Run the standard process
cmAsIslam5 <- assessRatings(vecMatrix=movAsIs250lam5$par, mtxY=movieRatings, mtxR=mtxSparse, 
                            nUser=ncol(movieRatings), nMovie=nrow(movieRatings), nFeature=ncol(mtxTheta), 
                            lambda=useLambda, useTitle="As-Is CG 250 (R == 1)"
                            )
cmAsIslam5

# Report back the costs using lambda=0 (true prediction error) and lambda=10 (regularized prediction error)
cofiCost(vecMatrix=movAsIs250lam5$par, mtxY=movieRatings, mtxR=mtxSparse, 
         nUser=ncol(movieRatings), nMovie=nrow(movieRatings), nFeature=ncol(mtxTheta), lambda=0
         )
cofiCost(vecMatrix=movAsIs250lam5$par, mtxY=movieRatings, mtxR=mtxSparse, 
         nUser=ncol(movieRatings), nMovie=nrow(movieRatings), nFeature=ncol(mtxTheta), lambda=10
         )

```
  
###_Summarizing Costs and Accuracies by Model_  
First, the relevant costs for lambda=0 (prediction cost) and lambda=10 (theta penalty) are calculated for the instructor input as well as the relevant models in this program.  Further, the relevant accuracies are pulled out as well for plotting:  
```{r}

# Grab the relevant costs
# Costs will be Original - Normalized - As-Is (run with lambda=10) - As-Is (run with lambda=5)
modCosts <- matrix(data=0, nrow=4, ncol=3)
dimnames(modCosts)[[1]] <- c("Original", "Normalized (lambda=10)", 
                             "As-Is (lambda=10)", "As-Is (lambda=5)"
                             )
dimnames(modCosts)[[2]] <- c("Cost iff lambda=0", "Cost iff lambda=10", "In-Sample Accuracy")

# Original Instructor Data
modCosts[1, 1] <- cofiCost(vecMatrix = c(as.vector(mtxX), as.vector(mtxTheta)), mtxY = movieRatings, 
                           mtxR = mtxSparse, nUser=nUser, nMovie=nMovie, nFeature=nFeature, lambda=0
                           )
modCosts[1, 2] <- cofiCost(vecMatrix = c(as.vector(mtxX), as.vector(mtxTheta)), mtxY = movieRatings, 
                           mtxR = mtxSparse, nUser=nUser, nMovie=nMovie, nFeature=nFeature, lambda=10
                           )

# Normalized Data
modCosts[2, 1] <- cofiCost(vecMatrix = movNorm250$par, mtxY = normRatings, 
                           mtxR = mtxSparse, nUser=nUser, nMovie=nMovie, nFeature=nFeature, lambda=0
                           )
modCosts[2, 2] <- cofiCost(vecMatrix = movNorm250$par, mtxY = normRatings, 
                           mtxR = mtxSparse, nUser=nUser, nMovie=nMovie, nFeature=nFeature, lambda=10
                           )

# As-Is Data (run as lambda 10)
modCosts[3, 1] <- cofiCost(vecMatrix = movAsIs250$par, mtxY = movieRatings, 
                           mtxR = mtxSparse, nUser=nUser, nMovie=nMovie, nFeature=nFeature, lambda=0
                           )
modCosts[3, 2] <- cofiCost(vecMatrix = movAsIs250$par, mtxY = movieRatings, 
                           mtxR = mtxSparse, nUser=nUser, nMovie=nMovie, nFeature=nFeature, lambda=10
                           )

# As-Is Data (run as lambda 5)
modCosts[4, 1] <- cofiCost(vecMatrix = movAsIs250lam5$par, mtxY = movieRatings, 
                           mtxR = mtxSparse, nUser=nUser, nMovie=nMovie, nFeature=nFeature, lambda=0
                           )
modCosts[4, 2] <- cofiCost(vecMatrix = movAsIs250lam5$par, mtxY = movieRatings, 
                           mtxR = mtxSparse, nUser=nUser, nMovie=nMovie, nFeature=nFeature, lambda=10
                           )

# Add the accuracies as Column 3
modCosts[ , 3] <- c(cmOrig$overall[[1]], cmNorm$overall[[1]], 
                    cmAsIs$overall[[1]], cmAsIslam5$overall[[1]]
                    )
```
  
Then, a plot is created for the costs by algorithm, and another plot is created for the accuracies by algorithm:  
```{r}

# Plot #1 - Costs by Model
barplot(modCosts[,2]/1000, xlab="Model", ylab="Cost (000s)", col="light blue", ylim=c(0, 100), 
        main="Costs by Model (In-Sample Error, Theta Penalty)", cex.lab=1.5, cex.main=1.5
        )
barplot(modCosts[,1]/1000, col="dark green", add=TRUE)
abline(h=c(modCosts[1,1], modCosts[1,2])/1000, lty=2)
legend("top", legend=c("Theta Penalty run @ lambda=10", "In-Sample Error Cost"), pch=15, pt.cex=2,
       col=c("light blue", "dark green")
       )

# Plot #2 - Accuracies by Model
plot(x=1:4, y=modCosts[,3], type="p", col="blue", pch=19, cex=2, ylim=c(0.3, 0.6), xaxt="n", 
     cex.lab=1.5, cex.main=1.5,
     ylab="Accuracy", xlab="Model", main="Accuracy (rounded predictions vs. actual)"
     )
axis(1, at=c(1.2, 2, 3, 3.8), labels=dimnames(modCosts)[[1]], tick=FALSE)
text(x=1:4, y=modCosts[,3]-0.025, labels=round(modCosts[, 3], 3), col="blue", cex=0.75)
abline(h=c(modCosts[1,3], cmOrig$overall[[5]]), lty=2, lwd=c(1, 2), col=c("black", "red"))
legend("top", col=c("black", "red"), lty=2, lwd=c(1,2), 
       legend=c(paste0("Original Model Accuracy: ", round(modCosts[1,3], 3)), 
                paste0("Null Accuracy (NIR): ", round(cmOrig$overall[[5]], 3))
                )
       )

```
  
Further, a boxplot is created showing the similarity of the recommendations made by the normalized (lambda=10) and as-is (lambda=10) models:  
```{r}

# Get the normalized predictions
predNorm <- assessRatings(vecMatrix=movNorm250$par, mtxY=normRatings, mtxR=mtxSparse, getPredOnly=TRUE,
                          nUser=ncol(normRatings), nMovie=nrow(normRatings), nFeature=ncol(mtxTheta),
                          lambda=useLambda, normData=movAvg
                          )
# Get the as-is predictions
predAsIs <- assessRatings(vecMatrix=movAsIs250$par, mtxY=movieRatings, mtxR=mtxSparse, getPredOnly=TRUE,
                          nUser=ncol(movieRatings), nMovie=nrow(movieRatings), nFeature=ncol(mtxTheta),
                          lambda=useLambda
                          )
# Get the original predictions (note that lambda is not actually called)
predOrig <- assessRatings(vecMatrix = c(as.vector(mtxX), as.vector(mtxTheta)), mtxY=movieRatings, 
                          mtxR=mtxSparse, getPredOnly=TRUE, nUser=ncol(movieRatings), 
                          nMovie=nrow(movieRatings), nFeature=ncol(mtxTheta), lambda=useLambda
                          )
# Get the lambda5 predictions (note that lambda is not actually called)
predLam5 <- assessRatings(vecMatrix=movAsIs250lam5$par, mtxY=movieRatings, mtxR=mtxSparse, getPredOnly=TRUE,
                          nUser=ncol(movieRatings), nMovie=nrow(movieRatings), nFeature=ncol(mtxTheta), 
                          lambda=useLambda
                          )

# Create the first boxplot and confusionMatrix
asisRatings <- pmax(1, pmin(5, predAsIs[mtxSparse==1] ) )
normRatings <- pmax(1, pmin(5, round(predNorm, 0)[mtxSparse==1] ) )
boxplot(asisRatings ~ normRatings, col="light blue", ylab="As-Is Rating (Bounded to 1-5)", 
        xlab="Normalized Rating (Rounded)", main="Rounded Normalized vs. Bounded As-Is"
        )
confusionMatrix(round(asisRatings,0), normRatings)

# Create the second boxplot and confusionMatrix
lam5Ratings <- pmax(1, pmin(5, predLam5[mtxSparse==1] ) )
origRatings <- pmax(1, pmin(5, round(predOrig, 0)[mtxSparse==1] ) )
boxplot(lam5Ratings ~ origRatings, col="light blue", ylab="Lambda=5 As-Is Rating (Bounded to 1-5)", 
        xlab="Original Inputs Rating (Rounded)", main="Rounded Original Inputs vs. Bounded Lambda=5"
        )
confusionMatrix(round(lam5Ratings,0), origRatings)

```

