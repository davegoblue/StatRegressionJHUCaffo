---
title: "Collaborative Filtering"
author: "davegoblue"
date: "June 15, 2016"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Background and Overview  
Collaborative filtering is an algorithm explored in the Ng Coursera "Machine Learning" course.  I am curious about the implications of choosing to normalize the response variable (movie rating) by subtracting its mean, as opposed to allowing the system to determine how to account for different movies having different means.  

## Analysis
###_Data Loading_  
Data is loaded from the MATLAB files that were supplied during the course.  Specifically, there is data on:  
  
* Matrices for movie ratings by user/movie  
* Initial theta matrices for predicting movie ratings as supplied by the instructors  
  
The data are loaded and inspected using the R.matlab() library:
```{r}
library(R.matlab, quietly=TRUE)

# Part 1: Load the movie ratings

matPath <- "../../../OctaveDirectory/Week09/"  # Using relative path
wgtData <- "ex8_movies.mat"

listMATData <- readMat(paste0(matPath, wgtData))
str(listMATData)  # Check that as expected - list with two items, $Y, $R

# Movie ratings are the ratings (movie x user)
# mtxSparse is a 1/0 indicator for whether the user has rated the movie
movieRatings <- listMATData$Y
mtxSparse <- listMATData$R

str(movieRatings)  # Validate that 1682x943 matrix (1682 movies, 943 users)
str(mtxSparse)  # Validate that 1682x943 matrix


# Part 2: Load the initial thetas

matPath <- "../../../OctaveDirectory/Week09/"  # Using relative path
wgtData <- "ex8_movieParams.mat"

listMATData <- readMat(paste0(matPath, wgtData))

# Will only keep the $X and $Theta items; other fields can be derived
str(listMATData)

mtxX <- listMATData$X
mtxTheta <- listMATData$Theta

str(mtxX)  # Validate that 1682x10 matrix (1682 movies, 10 features)
str(mtxTheta)  # Validate that 943x10 matrix (943 users, 10 features)

```
  
###_Function Declarations for Optimization_  
Next, functions are created to enable optimization to be run.  The functions include a cost calculation and then a gradient calculation:  
```{r}

cofiCost <- function(vecMatrix, mtxY, mtxR, nUser, nMovie, nFeature, lambda) {
    
    # Roll vecMatrix back to feature matrix and theta matrix
    keyCut <- nMovie * nFeature
    vecX <- vecMatrix[1:keyCut]
    vecTheta <- vecMatrix[(keyCut+1):length(vecMatrix)]
    useX <- matrix(data=vecX, nrow=nMovie, ncol=nFeature, byrow=FALSE)
    useTheta <- matrix(data=vecTheta, nrow=nUser, ncol=nFeature, byrow=FALSE)
    
    # Calculate cost
    movJ <- 0.5 * sum( ( (useX %*% t(useTheta) - mtxY)^2)[mtxR==1] )
    movJ <- movJ + 0.5 * lambda * ( sum(useX^2) + sum(useTheta^2) )
    
    return(movJ)
}

cofiGrad <- function(vecMatrix, mtxY, mtxR, nUser, nMovie, nFeature, lambda) {
    
    # Roll vecMatrix back to feature matrix and theta matrix
    keyCut <- nMovie * nFeature
    vecX <- vecMatrix[1:keyCut]
    vecTheta <- vecMatrix[(keyCut+1):length(vecMatrix)]
    useX <- matrix(data=vecX, nrow=nMovie, ncol=nFeature, byrow=FALSE)
    useTheta <- matrix(data=vecTheta, nrow=nUser, ncol=nFeature, byrow=FALSE)
    
    # Calculate gradients
    gradX <- ((useX %*% t(useTheta) - mtxY) * mtxR) %*% useTheta + (lambda * useX)
    gradTheta <- t((useX %*% t(useTheta) - mtxY) * mtxR) %*% useX + (lambda * useTheta)
    
    return(c(as.vector(gradX), as.vector(gradTheta)))
    
}

```
  
Further, the cost function is tested to ensure that it is consistent with the results the professor suggests to expect:  
```{r}
# Modify them for the test
nUser <- 4
nMovie <- 5
nFeature <- 3

# Validate that ~22.22
cofiCost(vecMatrix = c(as.vector(mtxX[1:nMovie, 1:nFeature]), as.vector(mtxTheta[1:nUser, 1:nFeature])),
         mtxY = movieRatings[1:nMovie, 1:nUser], mtxR = mtxSparse[1:nMovie, 1:nUser], nUser=nUser,
         nMovie=nMovie, nFeature=nFeature, lambda=0
         )

# Validate that ~31.34
cofiCost(vecMatrix = c(as.vector(mtxX[1:nMovie, 1:nFeature]), as.vector(mtxTheta[1:nUser, 1:nFeature])),
         mtxY = movieRatings[1:nMovie, 1:nUser], mtxR = mtxSparse[1:nMovie, 1:nUser], nUser=nUser,
         nMovie=nMovie, nFeature=nFeature, lambda=1.5
         )

# Capture these properly for remainder of program
nUser <- nrow(mtxTheta)
nMovie <- nrow(mtxX)
nFeature <- ncol(mtxX)

# Confirm that runs OK for full dataset also
cofiCost(vecMatrix = c(as.vector(mtxX), as.vector(mtxTheta)), mtxY = movieRatings, 
         mtxR = mtxSparse, nUser=nUser, nMovie=nMovie, nFeature=nFeature, lambda=0
         )
# Confirm that runs OK for full dataset also
cofiCost(vecMatrix = c(as.vector(mtxX), as.vector(mtxTheta)), mtxY = movieRatings, 
         mtxR = mtxSparse, nUser=nUser, nMovie=nMovie, nFeature=nFeature, lambda=10
         )

```
  
It appears that the cost function is working as it should.  The cost using the instructors inputs is 74,000 of which 28,000 is driven by mismatched movies, and 46,000 is driven by penalties induced by lambda=10.
  
###_Assessing Movie Recommendations_  
The quality of the movie recommendations depends on the degree of similarity between the predictions and the actual ratings, assessed only where a rating has been given.  A function is created to predict the approrpiate ratings and to plot their relationship to the actual ratings:  
```{r}
assessRatings <- function(vecMatrix, mtxY, mtxR, nUser, nMovie, nFeature, lambda, 
                          useTitle=FALSE, normData=NULL
                          ) {
    
    # Roll vecMatrix back to feature matrix and theta matrix
    keyCut <- nMovie * nFeature
    vecX <- vecMatrix[1:keyCut]
    vecTheta <- vecMatrix[(keyCut+1):length(vecMatrix)]
    useX <- matrix(data=vecX, nrow=nMovie, ncol=nFeature, byrow=FALSE)
    useTheta <- matrix(data=vecTheta, nrow=nUser, ncol=nFeature, byrow=FALSE)

    # Calculate the projected movie ratings
    predRatings <- useX %*% t(useTheta)
    
    # Add back the means if requested
    if (length(normData) > 0) {
        # Add the averages back to the predictions
        predRatings <- predRatings + normData * mtxR
        # Add the averages back to the raw data
        mtxY <- mtxY + normData * mtxR
    }
    
    # Create the confusion matrix assuming all ratings are forced to be 1-5
    cmRound <- confusionMatrix(pmin(5, pmax(1, round(predRatings[mtxR==1], 0) ) ), mtxY[mtxR==1])
    
    # Create the lm, and without assuming all ratings are forced to be 1-5
    lmAssess <- lm(predRatings[mtxR==1] ~ mtxY[mtxR==1])
    print(summary(lmAssess))
    
    par(mfrow=c(1, 2))
    
    # Create a histogram of the ratings
    hist(x=predRatings[mtxR==1], col=rgb(0.5,0,0,0.25), xlab="Rating", 
         main=ifelse(useTitle == FALSE, "Instructor Inputs (R == 1)", useTitle),
         breaks=seq(-2.5,7.5,by=1)
         )
    hist(x=mtxY[mtxR==1], col=rgb(0,0,0.5,0.25), add=TRUE, breaks=seq(-2.5,7.5,by=1))
    legend("topleft", legend=c("Actual", "Predicted", "Overlap"), pch=20, cex=0.9, pt.cex=3,
           col=c(rgb(0,0,0.5,0.25), rgb(0.5,0,0,0.25), rgb(0.25,0,0.25,0.5))
           )
    
    # Create a boxplot of the ratings
    trueRatings <- 0.5 * round(2*mtxY, 0)[mtxR==1]
    boxplot(predRatings[mtxR==1] ~ trueRatings, col="light blue", 
            xlab="Actual Rating", ylab="Predicted Rating",
            main=ifelse(useTitle == FALSE, "Instructor Inputs (R == 1)", useTitle)
            )
    text(x=2.2, y=0.3, paste0("R^2: ", round(summary(lmAssess)$r.squared, 2) ), adj=c(0, 0), cex=0.8 )
    text(x=2.2, y=-0.1, paste0("Accur: ", round(cmRound$overall[[1]], 2) ), adj=c(0, 0) , cex=0.8)
    text(x=4, y=0.3, paste0("Inter: ", round(coef(lmAssess)[[1]], 2) ), adj=c(0, 0) , cex=0.8)
    text(x=4, y=-0.1, paste0("Slope: ", round(coef(lmAssess)[[2]], 2) ), adj=c(0, 0) , cex=0.8)
    
    
    par(mfrow=c(1, 1))
    
    return(cmRound)
}
```
  
Next, the function is called to check the instructors inputs:  
```{r}
library(caret, quietly=TRUE)

# Assess the original movie data from the instructor
assessRatings(vecMatrix = c(as.vector(mtxX), as.vector(mtxTheta)), mtxY = movieRatings, 
              mtxR = mtxSparse, nUser=nUser, nMovie=nMovie, nFeature=nFeature, lambda=10
              )

```
  
###_Creating Movie Recommendations (Normalized)_  
Creating movie recommendations requires two steps.  First, input values need to be randomized in to the prediction matrices, to ensure that the symmetries are broken.  Second, the inputs need to be optimized, whether using mini-batch, a global optimizer, or some other technique.  
  
For this example, we will further take the step of normalizing (subtracting the mean) all actual movie ratings prior to the optimization.  This means that thetas will not need to do any work coming up with the mean component, a significant savings when all coefficient-squared are penalized by 10.  
  
First, the lambda parameter is set to 10, the random initial matrices are set, and the normalized ratings data are created:  
```{r}
useLambda=10

# Initialize mtxX and mtxTheta using N(0, 1) -- seems very high, but done to match Octave
set.seed(1615161453)
simTheta <- matrix(rnorm(length(mtxTheta)), nrow=nrow(mtxTheta))
simX <- matrix(rnorm(length(mtxX)), nrow=nrow(mtxX))

# Create the movie averages and normalized ratings
movSum <- apply(movieRatings, 1, FUN=sum)
movCount <- apply(mtxSparse, 1, FUN=sum)
movAvg <- movSum / movCount

normRatings <- movieRatings - movAvg * mtxSparse
```
  
Next, optimization is run using the CG method capped at 250 iterations.  This is cached to avoid continually processing the same data:  
```{r, cache=TRUE}

vecMatrix = c(as.vector(simX), as.vector(simTheta))

startTime <- proc.time()
movNorm250 <- optim(par=vecMatrix, fn=cofiCost, gr=cofiGrad, mtxY=normRatings, mtxR=mtxSparse,
                    nUser=ncol(normRatings), nMovie=nrow(normRatings), nFeature=ncol(mtxTheta), 
                    lambda=useLambda, control=list(maxit=250), method="CG"
                 )
proc.time() - startTime

```
  
Then, the normalized movie ratings are assessed, with the request to add back the movie averages everywhere:  
```{r}
# Run the standard process
assessRatings(vecMatrix=movNorm250$par, mtxY=normRatings, mtxR=mtxSparse, 
              nUser=ncol(normRatings), nMovie=nrow(normRatings), nFeature=ncol(mtxTheta), 
              lambda=useLambda, useTitle="Normalized CG 250 (R == 1)", normData=movAvg
              )

# Report back the costs using lambda=0 (true prediction error) and lambda=10 (regularized prediction error)
cofiCost(vecMatrix=movNorm250$par, mtxY=normRatings, mtxR=mtxSparse, 
         nUser=ncol(normRatings), nMovie=nrow(normRatings), nFeature=ncol(mtxTheta), lambda=0
         )
cofiCost(vecMatrix=movNorm250$par, mtxY=normRatings, mtxR=mtxSparse, 
         nUser=ncol(normRatings), nMovie=nrow(normRatings), nFeature=ncol(mtxTheta), lambda=10
         )

```
  
###_Creating Movie Recommendations (Non-Normalized)_  
In this step, we instead use the raw movie ratings in the algorithm, running the same process as before.  The same initial theta matrix is used for consistency, though this likely disadvantages the non-normalized process since it will need to seek out a surrogate for intercept.  Optimization is again run for CG 250:  
```{r, cache=TRUE}

vecMatrix = c(as.vector(simX), as.vector(simTheta))

startTime <- proc.time()
movAsIs250 <- optim(par=vecMatrix, fn=cofiCost, gr=cofiGrad, mtxY=movieRatings, mtxR=mtxSparse,
                    nUser=ncol(movieRatings), nMovie=nrow(movieRatings), nFeature=ncol(mtxTheta), 
                    lambda=useLambda, control=list(maxit=250), method="CG"
                 )
proc.time() - startTime

```
  
And, the predicted movie ratings are assessed, defaulted to leave all of the movie averages alone:  
```{r}
# Run the standard process
assessRatings(vecMatrix=movAsIs250$par, mtxY=movieRatings, mtxR=mtxSparse, 
              nUser=ncol(movieRatings), nMovie=nrow(movieRatings), nFeature=ncol(mtxTheta), 
              lambda=useLambda, useTitle="As-Is CG 250 (R == 1)"
              )

# Report back the costs using lambda=0 (true prediction error) and lambda=10 (regularized prediction error)
cofiCost(vecMatrix=movAsIs250$par, mtxY=movieRatings, mtxR=mtxSparse, 
         nUser=ncol(movieRatings), nMovie=nrow(movieRatings), nFeature=ncol(mtxTheta), lambda=0
         )
cofiCost(vecMatrix=movAsIs250$par, mtxY=movieRatings, mtxR=mtxSparse, 
         nUser=ncol(movieRatings), nMovie=nrow(movieRatings), nFeature=ncol(mtxTheta), lambda=10
         )

```

